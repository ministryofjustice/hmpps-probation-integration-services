{
  "description": "Split text into chunks and generate embeddings",
  "processors": [
    {
      "text_chunking": {
        "algorithm": {
          "fixed_token_length": {
            "token_limit": 128,
            "overlap_rate": 0.125,
            "tokenizer": "standard"
          }
        },
        "field_map": {
          "notes": "textChunks"
        }
      }
    },
    {
      "append": {
        "field": "textChunks",
        "value": [
          "{{{date}}} {{{startTime}}}",
          "{{{typeDescription}}} {{{typeShortDescription}}}",
          "{{{outcomeDescription}}}",
          "{{{description}}}"
        ]
      }
    },
    {
      "text_embedding": {
        "model_id": "${model_id}",
        "field_map": {
          "textChunks": "textEmbedding"
        }
      }
    }
  ]
}